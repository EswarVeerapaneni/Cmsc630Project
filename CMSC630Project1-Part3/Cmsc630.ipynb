{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfRw7R0UXGzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7179661-5b07-4740-d59e-9ad90ae96a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "# path of images\n",
        "dir_path = r'/content/'\n",
        "# create two empty list to storea images and the labels\n",
        "images = []\n",
        "labels = {'1': 'black', '2': 'red', '3': 'green', '4': 'blue', '5': 'purple'}\n",
        "label = {}\n",
        "image_labels = []\n",
        "# loop through all files in the directory\n",
        "for fName in os.listdir(dir_path):\n",
        "    # check if file is an image (we assume all BMP files are images)\n",
        "    if fName.endswith('.BMP'):\n",
        "        for key, value in labels.items():\n",
        "            if value in fName:\n",
        "                label = key\n",
        "                break     \n",
        "        # construct full file path\n",
        "        f_path = os.path.join(dir_path, fName)\n",
        "        # load image\n",
        "        img = cv2.imread(f_path) \n",
        "        images.append(img)\n",
        "        image_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_histogram(image):\n",
        "    # Initialize an array of zeros with 256 elements to represent the histogram\n",
        "    histogram = np.zeros((256,), dtype=int)\n",
        "    # Iterate over each pixel in the image and increment the corresponding histogram bin\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            histogram[image[i, j]] += 1\n",
        "    # Return the histogram array\n",
        "    return histogram\n",
        "\n",
        "def convert_to_single_color(image, color='red'):\n",
        "    # Check if the specified color is valid\n",
        "    if color not in ['red', 'green', 'blue']:\n",
        "        raise ValueError(\"Invalid color specified. Must be 'red', 'green', or 'blue'.\")\n",
        "    # Create a grayscale image by extracting the specified color channel from the input image\n",
        "    gray = np.zeros_like(image[:, :, 0])   \n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            if color == 'red':\n",
        "                gray[i, j] = image[i, j, 0]\n",
        "            elif color == 'green':\n",
        "                gray[i, j] = image[i, j, 1]\n",
        "            else:\n",
        "                gray[i, j] = image[i, j, 2]\n",
        "    # Return the grayscale image\n",
        "    return gray\n",
        "\n",
        "def histogram_equalization(image):\n",
        "    # Compute the histogram of the input image\n",
        "    hist, bins = np.histogram(image.flatten(), 256, [0,256])\n",
        "    # Compute the cumulative distribution function of the histogram\n",
        "    distr = hist.cumsum()\n",
        "    # Normalize the cumulative distribution function to the range [0, 255]\n",
        "    intensity = np.ma.masked_equal(distr * hist.max() / distr.max(),0)\n",
        "    intensity = (intensity - intensity.min())*255/(intensity.max()-intensity.min())\n",
        "    distr = np.ma.filled(intensity,0).astype('uint8')\n",
        "    # Apply the histogram equalization transformation to the input image using the computed mapping\n",
        "    return distr[image]\n",
        "\n",
        "gray_images = []\n",
        "histograms = []\n",
        "equalized_histogram = []\n",
        "equalized_histograms = []\n",
        "i = 0\n",
        "for img in images:\n",
        "    i = i +1\n",
        "    #gray_img = convert_to_single_color(img)\n",
        "    gray_images.append(img)\n",
        "#s    cv2.imwrite(r'C:\\Users\\Eswar' + '\\'' + 's Dell\\Downloads\\Cancerous cell smears 2023'+'temp'+ str(i) +'.BMP', gray_img)\n",
        "#     histogram = calculate_histogram(gray_img)\n",
        "#     equalized_histogram = histogram_equalization(gray_img)\n",
        "#     histograms.append(histogram)\n",
        "#     equalized_histograms.append(equalized_histogram)\n",
        "#     print(f'Histogram for image {i}: {histogram}')\n",
        "\n",
        "# with open('histograms.txt', 'w') as f:\n",
        "#     for i, histogram in enumerate(histograms):\n",
        "#         f.write(f'Histogram for image {i+1}: {histogram}\\n')\n",
        "\n",
        "# Load segmented cell image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def histogram_thresholding(img):\n",
        "    # Calculate histogram of pixel intensities\n",
        "    hist, bins = np.histogram(img.flatten(), 256, [0,256])\n",
        "    \n",
        "    # Find threshold value that maximizes variance between classes\n",
        "    max_var = 0\n",
        "    threshold = 0\n",
        "    for t in range(256):\n",
        "        # Class probabilities\n",
        "        p1 = np.sum(hist[:t]) / img.size\n",
        "        p2 = np.sum(hist[t:]) / img.size\n",
        "        \n",
        "        # Class means\n",
        "        m1 = np.sum(np.arange(t) * hist[:t]) / np.sum(hist[:t])\n",
        "        m2 = np.sum(np.arange(t, 256) * hist[t:]) / np.sum(hist[t:])\n",
        "        \n",
        "        # Between-class variance\n",
        "        var = p1 * p2 * (m1 - m2)**2\n",
        "        \n",
        "        if var > max_var:\n",
        "            max_var = var\n",
        "            threshold = t\n",
        "    \n",
        "    # Create binary image using threshold\n",
        "    binary = np.zeros_like(img)\n",
        "    binary[img >= threshold] = 255\n",
        "    \n",
        "    return binary\n",
        "\n",
        "applyHistogramThreshold = []\n",
        "applyHistogramThresholds = []\n",
        "\n",
        "for gray_img in gray_images:\n",
        "    applyHistogramThreshold = histogram_thresholding(gray_img)\n",
        "    applyHistogramThresholds.append(applyHistogramThreshold)\n",
        "\n",
        "def apply_linear_filter(image, mask, weights):\n",
        "    # Get the image's dimensions.\n",
        "    h, w = image.shape[:2]\n",
        "    # Make a blank output image.\n",
        "    result = np.zeros_like(image)\n",
        "    weights = np.reshape(weights, (mask, mask))\n",
        "    # Each pixel in the image should receive the linear filter.\n",
        "    for i in range(mask // 2, h - mask // 2):\n",
        "        for j in range(mask // 2, w - mask // 2):\n",
        "            # Remove the mask from the source image.\n",
        "            maska = image[i - mask // 2:i + mask // 2 + 1, j - mask // 2:j + mask // 2 + 1]\n",
        "            # Calculate the mask's weighted sum of the pixels.\n",
        "            sum = np.sum(maska * weights)\n",
        "            # Keep the outcome in the final image.\n",
        "            result[i, j] = sum\n",
        "    # Bring up the result image\n",
        "    return result\n",
        "\n",
        "def median_filter(image, mask_size):\n",
        "    # Get the dimensions of the input image\n",
        "    r, c = image.shape\n",
        "    # Pad the input image with reflection of the border pixels\n",
        "    pad = np.pad(image, mask_size // 2, mode='reflect')\n",
        "    # Create an empty output image of the same shape as the input image\n",
        "    filterI = np.zeros_like(image)   \n",
        "    # Iterate over each pixel in the original image\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            # Extract a mask_size x mask_size neighborhood centered on the pixel\n",
        "            sur = pad[i:i+mask_size, j:j+mask_size].flatten()\n",
        "            # Sort the neighborhood values and set the pixel value to the median\n",
        "            filterI[i, j] = np.sort(sur)[len(sur) // 2]\n",
        "    # Return the filtered image\n",
        "    return filterI\n",
        "\n",
        "def salt_and_pepper(img, strength):\n",
        "    # Get the dimensions of the input image\n",
        "    height, width = img.shape\n",
        "    # Create a copy of the input image to add noise to\n",
        "    noisy_img = img.copy()\n",
        "    # Set approximately strength/2 fraction of the pixels to black (0)\n",
        "    noisy_img[np.random.rand(height, width) < strength/2] = 0\n",
        "    # Set approximately strength/2 fraction of the pixels to white (255)\n",
        "    noisy_img[np.random.rand(height, width) > 1 - strength/2] = 255\n",
        "    # Return the noisy image\n",
        "    return noisy_img\n",
        "\n",
        "def gaussian_noise(image, mean, standardDeviation):\n",
        "    # Generate an array of the same shape as the input image by sampling from a normal distribution\n",
        "    noise = np.random.normal(mean, standardDeviation, size=image.shape)\n",
        "    # Add the noise to the input image and clip the resulting values to the range [0, 255]\n",
        "    noisy_image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
        "    # Return the noisy image\n",
        "    return noisy_image\n",
        "\n",
        "gray_images = []\n",
        "histograms = []\n",
        "equalized_histogram = []\n",
        "equalized_histograms = []\n",
        "i = 0\n",
        "for img in images:\n",
        "    i = i +1\n",
        "    gray_img = convert_to_single_color(img)\n",
        "    gray_images.append(gray_img)\n",
        "    cv2.imwrite(r'C:\\Users\\Eswar' + '\\'' + 's Dell\\Downloads\\Cancerous cell smears 2023'+'temp'+ str(i) +'.BMP', gray_img)\n",
        "    histogram = calculate_histogram(gray_img)\n",
        "    equalized_histogram = histogram_equalization(gray_img)\n",
        "    histograms.append(histogram)\n",
        "    equalized_histograms.append(equalized_histogram)\n",
        "    print(f'Histogram for image {i}: {histogram}')\n",
        "\n",
        "with open('histograms.txt', 'w') as f:\n",
        "    for i, histogram in enumerate(histograms):\n",
        "        f.write(f'Histogram for image {i+1}: {histogram}\\n')\n",
        "\n",
        "c_histograms = {}\n",
        "avg_histograms = {}\n",
        "for label in labels.keys():\n",
        "    c_histograms[label] = []\n",
        "\n",
        "for index, histogram in enumerate(histograms):\n",
        "    label = image_labels[index]\n",
        "    c_histograms[label].append(histogram)\n",
        "\n",
        "for label, histograms in c_histograms.items():\n",
        "    avg_histograms[label] = np.mean(histograms, axis=0)\n",
        "\n",
        "with open('avg_histograms.txt', 'w') as f:\n",
        "    for label, histogram in avg_histograms.items():\n",
        "        f.write(f'Averaged histogram for class {labels[label]}: {histogram}\\n')\n",
        "\n",
        "with open('equal_histograms.txt', 'w') as f:\n",
        "    for i, equalized_histogram in enumerate(equalized_histograms):\n",
        "        f.write(f'Histogram for image {i+1}: {equalized_histogram}\\n')\n",
        "\n",
        "\n",
        "for img in images:\n",
        "    gray_img = convert_to_single_color(img)\n",
        "    gray_images.append(gray_img)\n",
        "\n",
        "getSaltNoice = []\n",
        "getSaltNoices = []\n",
        "choice = float(input(\"enter your choice for salt_and_pepper strength \"))\n",
        "for gray_img in gray_images:\n",
        "    getSaltNoice = salt_and_pepper(gray_img, strength= choice)\n",
        "    getSaltNoices.append(getSaltNoice)\n",
        "\n",
        "with open('salt_pepper_Noice.txt', 'w') as f:\n",
        "    for i, getSaltNoice in enumerate(getSaltNoices):\n",
        "        f.write(f'salt_pepper noice for image {i+1}: {getSaltNoice}\\n')\n",
        "\n",
        "getMean = float(input(\"enter your choice of mean value for gaussian_noise\"))\n",
        "getStd = float(input(\"enter your value of standard deviation for gaussian_noise \"))\n",
        "\n",
        "getGaussian = []\n",
        "getGaussians = []\n",
        "for gray_img in gray_images:\n",
        "    getGaussian = gaussian_noise(gray_img, mean= getMean, standardDeviation= getStd)\n",
        "    getGaussians.append(getGaussian)\n",
        "\n",
        "with open('gaussian_noise.txt', 'w') as f:\n",
        "    for i, getGaussian in enumerate(getGaussians):\n",
        "        f.write(f'gaussian_noise noice for image {i+1}: {getGaussian}\\n')\n",
        "\n",
        "pic =  np.random.rand(100,100)\n",
        "mask_size = int(input(\"enter the mask size for linear filter\"))\n",
        "weights = []\n",
        "\n",
        "for x in range(mask_size*mask_size):\n",
        "    weight = int(input(\"enter \" + str(mask_size*mask_size) + \" weights: \"))\n",
        "    weights.append(weight)\n",
        "\n",
        "getLinearFilterImg = []\n",
        "getLinearFilterImgs = []\n",
        "for gray_img in gray_images:\n",
        "    getLinearFilterImg = apply_linear_filter(gray_img, mask = mask_size, weights= weights)\n",
        "    getLinearFilterImgs.append(getLinearFilterImg)\n",
        "\n",
        "with open('apply_linear_filter.txt', 'w') as f:\n",
        "    for i, getLinearFilterImg in enumerate(getLinearFilterImgs):\n",
        "        f.write(f'apply_linear_filter filter for image {i+1}: {getLinearFilterImg}\\n')\n",
        "\n",
        "\n",
        "getMedianFilterImg = []\n",
        "getMedianFilterImgs = []\n",
        "mask_size = int(input(\"enter the mask size for median filter\"))\n",
        "for gray_img in gray_images:\n",
        "    getMedianFilterImg = median_filter(gray_img, mask_size = mask_size)\n",
        "    getMedianFilterImgs.append(getMedianFilterImg)\n",
        "\n",
        "with open('median_filter.txt', 'w') as f:\n",
        "    for i, getMedianFilterImg in enumerate(getMedianFilterImgs):\n",
        "        f.write(f'median_filter filter for image {i+1}: {getMedianFilterImg}\\n')\n",
        "\n",
        "def sobel_edge(img):\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray_img = img\n",
        "    blur = gaussian_noise(gray_img, mean= 2, standardDeviation= 2)\n",
        "    sobel_x = cv2.Sobel(blur, cv2.CV_64F, 1, 0, ksize=5)\n",
        "    sobel_y = cv2.Sobel(blur, cv2.CV_64F, 0, 1, ksize=5)\n",
        "    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "    finalImage = np.zeros_like(magnitude)\n",
        "    finalImage[(magnitude >= np.percentile(magnitude, 50)) & (magnitude <= np.percentile(magnitude, 90))] = 1\n",
        "\n",
        "    return finalImage\n",
        "\n",
        "getSobelDetectedImage = []\n",
        "getSobelDetectedImages = []\n",
        "\n",
        "for gray_img in gray_images:\n",
        "    getSobelDetectedImage = sobel_edge(gray_img)\n",
        "    getSobelDetectedImages.append(getSobelDetectedImage)\n",
        "\n",
        "\n",
        "with open('sobel_Edge.txt', 'w') as f:\n",
        "    for i, getSobelDetectedImage in enumerate(getSobelDetectedImages):\n",
        "        f.write(f'sobel filter for image {i+1}: {getSobelDetectedImage}\\n')\n",
        "        print(f'sobel filter for image {i+1}: {getSobelDetectedImage}\\n')\n",
        "\n",
        "\n",
        "def dilation(img, kernel):\n",
        "    pad = np.pad(img, (kernel.shape[0] // 2), mode='constant', constant_values=0)\n",
        "    final_Image = np.zeros_like(img) # creating output image of the same size as the padded image\n",
        "\n",
        "    for i in range(kernel.shape[0] // 2,(img.shape[0]+(kernel.shape[0] // 2)) ):\n",
        "        for j in range(kernel.shape[0] // 2, (img.shape[0]+(kernel.shape[0] // 2))):\n",
        "            kernel_centered = pad[i-(kernel.shape[0] // 2):i+(kernel.shape[0] // 2)+1, j-(kernel.shape[0] // 2):j+(kernel.shape[0] // 2)+1]\n",
        "            final_Image[i-(kernel.shape[0] // 2), j-(kernel.shape[0] // 2)] = np.max(kernel_centered * kernel)\n",
        "            print(i)\n",
        "    return final_Image\n",
        "\n",
        "\n",
        "def erosion(img, kernel):\n",
        "    img_padded = np.pad(img, (kernel.shape[0] // 2), mode='constant', constant_values=1)\n",
        "    final_Image = np.zeros_like(img)\n",
        "\n",
        "    for i in range((kernel.shape[0] // 2), img.shape[0]+(kernel.shape[0] // 2)):\n",
        "        for j in range((kernel.shape[0] // 2), img.shape[1]+(kernel.shape[0] // 2)):\n",
        "            kernel_centered = img_padded[i-(kernel.shape[0] // 2):i+(kernel.shape[0] // 2)+1, j-(kernel.shape[0] // 2):j+(kernel.shape[0] // 2)+1]\n",
        "            final_Image[i-(kernel.shape[0] // 2), j-(kernel.shape[0] // 2)] = np.min(kernel_centered * kernel)\n",
        "            print(i)\n",
        "\n",
        "    return final_Image\n",
        "\n",
        "\n",
        "getDilutedImage = []\n",
        "getDilutedImages = []\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "for gray_img in gray_images:\n",
        "    getDilutedImage = dilation(gray_img,kernel=kernel)\n",
        "    getDilutedImages.append(getDilutedImage)\n",
        "\n",
        "with open('dilation.txt', 'w') as f:\n",
        "    for i, getDilutedImage in enumerate(getDilutedImages):\n",
        "        f.write(f'dilation filter for image {i+1}: {getDilutedImage}\\n')\n",
        "        print(f'dilation filter for image {i+1}: {getDilutedImage}\\n')\n",
        "\n",
        "\n",
        "geterosionImage = []\n",
        "geterosionImages = []\n",
        "\n",
        "for gray_img in gray_images:\n",
        "    geterosionImage = erosion(gray_img,kernel=kernel)\n",
        "    geterosionImages.append(geterosionImage)\n",
        "\n",
        "with open('erosion.txt', 'w') as f:\n",
        "    for i, geterosionImage in enumerate(geterosionImages):\n",
        "        f.write(f'erosion filter for image {i+1}: {geterosionImage}\\n')\n",
        "        print(f'erosion filter for image {i+1}: {geterosionImage}\\n')\n",
        "1\n",
        "def histogram_thresholding(img):\n",
        "    hist, bins = np.histogram(img.flatten(), 256, [0,256])\n",
        "    max_var = 0\n",
        "    threshold = 0\n",
        "    for t in range(256):\n",
        "        p1 = np.sum(hist[:t]) / img.size\n",
        "        p2 = np.sum(hist[t:]) / img.size\n",
        "        m1 = np.sum(np.arange(t) * hist[:t]) / np.sum(hist[:t])\n",
        "        m2 = np.sum(np.arange(t, 256) * hist[t:]) / np.sum(hist[t:])\n",
        "        var = p1 * p2 * (m1 - m2)**2\n",
        "        \n",
        "        if var > max_var:\n",
        "            max_var = var\n",
        "            threshold = t\n",
        "    \n",
        "    binary = np.zeros_like(img)\n",
        "    binary[img >= threshold] = 255\n",
        "    \n",
        "    return binary\n",
        "\n",
        "applyHistogramThreshold = []\n",
        "applyHistogramThresholds = []\n",
        "\n",
        "for gray_img in gray_images:\n",
        "    applyHistogramThreshold = histogram_thresholding(gray_img)\n",
        "    applyHistogramThresholds.append(applyHistogramThreshold)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(img):\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    \n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    perimeter = cv2.arcLength(contours[0], True)\n",
        "    area = cv2.contourArea(contours[0])\n",
        "    \n",
        "    binary = np.zeros(gray.shape, np.uint8)\n",
        "    binary[edges > 0] = 1\n",
        "    my_range = 50\n",
        "    col_measure = np.sum(binary, axis=0)\n",
        "    row_measure = np.sum(binary, axis=1)\n",
        "    max_x = np.argmax(col_measure) + my_range\n",
        "    max_y = np.argmax(row_measure) + my_range\n",
        "    window = img[max_y - my_range:max_y + my_range, max_x - my_range:max_x + my_range, :]\n",
        "    meanR = int(np.mean(window[:, :, 0]))\n",
        "    meanG= int(np.mean(window[:, :, 1]))\n",
        "    meanB= int(np.mean(window[:, :, 2]))\n",
        "    \n",
        "    h = cv2.calcHist([gray[max_y - my_range:max_y + my_range, max_x - my_range:max_x + my_range]], [0], None, [256], [0, 256])\n",
        "    max_h_val = np.argmax(h)\n",
        "    \n",
        "    features = [perimeter, area, mean_r, mean_g, mean_b, max_h_val]\n",
        "    \n",
        "    return features\n",
        "\n",
        "import random\n",
        "labels = {'1': 'cyl', '2': 'inter', '3': 'let', '4': 'mod', '5': 'para', '6': 'super', '7': 'svar'}\n",
        "features = []\n",
        "for applyHistogramThreshold in applyHistogramThresholds:\n",
        "    feature = extract_features(applyHistogramThreshold)\n",
        "    label = labels[str(random.randint(1, 7))]\n",
        "    feature.append(label)\n",
        "    features.append(feature)\n",
        "    print(feature)\n",
        "data = np.hstack((features))\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('/content/sample_data/dataset1', index=False, header=False)\n",
        "\n",
        "class KNNClassifier:\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "    \n",
        "    def predict(self, X):\n",
        "        y_pred = np.zeros(X.shape[0], dtype=self.y_train.dtype)\n",
        "        for i, x in enumerate(X):\n",
        "            distances = np.sqrt(np.sum(np.square(self.X_train - x), axis=1))\n",
        "            nn_indices = np.argsort(distances)[:self.k]\n",
        "            nn_labels = self.y_train[nn_indices]\n",
        "            y_pred[i] = np.bincount(nn_labels).argmax()\n",
        "        return y_pred\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    knn = KNNClassifier(k=5)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
        "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")"
      ]
    }
  ]
}
